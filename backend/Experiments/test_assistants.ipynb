{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file-4FKpqlvJOZqxNUfIJHAHRGJY', 'file-TzOVAHko5TwyrRsaPySmIR0Z']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "files = ['contacts.csv', 'searches.csv']\n",
    "uploaded_files = [] \n",
    "\n",
    "# for f in files:\n",
    "#   file = client.files.create(\n",
    "#     file=open(f\"../data/{f}\", \"rb\"),\n",
    "#     purpose='assistants'\n",
    "#   )\n",
    "#   uploaded_files.append(file)\n",
    "\n",
    "# file_ids = [file.id for file in uploaded_files]\n",
    "\n",
    "file_ids = ['file-4FKpqlvJOZqxNUfIJHAHRGJY', 'file-TzOVAHko5TwyrRsaPySmIR0Z']\n",
    "file_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant using the file ID\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a personal chatbot assistant.\",\n",
    "  model=\"gpt-4-turbo\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  file_ids=file_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"which day of the week were the most bookings made?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_65lBESnXqLnniNHAI865s36W', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='which day of the week were the most bookings made?'), type='text')], created_at=1713076608, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_xkjf4vsQK6FTO68FKuSAmhk2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > To help you find which day of the week had the most bookings, I'll need to know the format and type of data in the files you've uploaded. Let's start by examining the contents of the files to understand the structure of the data, including how dates are recorded. I will then extract the necessary date information to assess on which day of the week the most bookings were made. Let me first check the content of the files you provided.\n",
      "assistant > code_interpreter\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load the files to see their content and format\n",
      "file_path1 = '/mnt/data/file-4FKpqlvJOZqxNUfIJHAHRGJY'\n",
      "file_path2 = '/mnt/data/file-TzOVAHko5TwyrRsaPySmIR0Z'\n",
      "\n",
      "# Since we don't know the file types, we'll try to guess by file extensions\n",
      "file_path1.split('.')[-1], file_path2.split('.')[-1]\n",
      "\n",
      "output >\n",
      "\n",
      "('/mnt/data/file-4FKpqlvJOZqxNUfIJHAHRGJY',\n",
      " '/mnt/data/file-TzOVAHko5TwyrRsaPySmIR0Z')\n",
      "\n",
      "assistant > It seems there was an issue determining the file types as the extensions weren't visible in the paths provided. I will attempt to open them as common data file types such as CSV or Excel to discover the correct format. Let's start by trying to read them as CSV files.# Attempt to load the files as CSVs and catch any exceptions if they fail\n",
      "try:\n",
      "    data1 = pd.read_csv(file_path1)\n",
      "    print(\"Data from first file loaded:\")\n",
      "    display(data1.head())\n",
      "except Exception as e1:\n",
      "    print(\"Failed to read first file as CSV:\", e1)\n",
      "\n",
      "try:\n",
      "    data2 = pd.read_csv(file_path2)\n",
      "    print(\"Data from second file loaded:\")\n",
      "    display(data2.head())\n",
      "except Exception as e2:\n",
      "    print(\"Failed to read second file as CSV:\", e2)\n",
      "\n",
      "output >\n",
      "\n",
      "Data from first file loaded:\n",
      "\n",
      "\n",
      "\n",
      "output >\n",
      "\n",
      "Data from second file loaded:\n",
      "\n",
      "\n",
      "assistant > Both files were successfully read as CSV files. Let's proceed by examining the column names of both datasets to find the relevant date information, which will help us determine which day of the week had the most bookings.# Display the column names from both datasets\n",
      "data1_columns = data1.columns\n",
      "data2_columns = data2.columns\n",
      "\n",
      "data1_columns, data2_columns\n",
      "\n",
      "output >\n",
      "\n",
      "(Index(['id_guest', 'id_host', 'id_listing', 'ts_contact_at', 'ts_reply_at',\n",
      "        'ts_accepted_at', 'ts_booking_at', 'ds_checkin', 'ds_checkout',\n",
      "        'n_guests', 'n_messages'],\n",
      "       dtype='object'),\n",
      " Index(['ds', 'id_user', 'ds_checkin', 'ds_checkout', 'n_searches', 'n_nights',\n",
      "        'n_guests_min', 'n_guests_max', 'origin_country', 'filter_price_min',\n",
      "        'filter_price_max', 'filter_room_types', 'filter_neighborhoods'],\n",
      "       dtype='object'))\n",
      "\n",
      "assistant > From the column names:\n",
      "\n",
      "- The first dataset (`data1`) includes a column named `'ts_booking_at'` which probably contains the timestamp when the booking was made.\n",
      "- The second dataset (`data2`) doesn't contain a specific booking timestamp but has columns like `'ds_checkin'` and `'ds_checkout'`.\n",
      "\n",
      "It seems that the first dataset (`data1`) is the appropriate one for analyzing the day of the week with the most bookings, considering it specifically includes a booking timestamp. Let's analyze `data1` to determine which day of the week had the most bookings. I'll convert the timestamps into weekdays and then count the occurrences of each day.# Convert the 'ts_booking_at' column to datetime\n",
      "data1['ts_booking_at'] = pd.to_datetime(data1['ts_booking_at'])\n",
      "\n",
      "# Extract the day of week (Monday=0, Sunday=6) and map it to weekday names\n",
      "data1['day_of_week'] = data1['ts_booking_at'].dt.day_name()\n",
      "\n",
      "# Count the occurrences of each day\n",
      "weekday_counts = data1['day_of_week'].value_counts()\n",
      "weekday_counts\n",
      "\n",
      "output >\n",
      "\n",
      "Monday       363\n",
      "Wednesday    362\n",
      "Thursday     327\n",
      "Tuesday      318\n",
      "Friday       309\n",
      "Sunday       253\n",
      "Saturday     242\n",
      "Name: day_of_week, dtype: int64\n",
      "\n",
      "assistant > The day of the week with the most bookings made is **Monday**, with a total of 363 bookings. If you need further analysis or additional information from your data, feel free to ask!"
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    " \n",
    "# First, we create a EventHandler class to define\n",
    "# how we want to handle the events in the response stream.\n",
    " \n",
    "class EventHandler(AssistantEventHandler):    \n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "      \n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "      \n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\noutput >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    " \n",
    "# Then, we use the `create_and_stream` SDK helper \n",
    "# with the `EventHandler` class to create the Run \n",
    "# and stream the response.\n",
    " \n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    "  event_handler=EventHandler(),\n",
    ") as stream:\n",
    "  stream.until_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GreanTeam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
